{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ababbd52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.sem import logic\n",
    "from nltk.sem import Expression\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bd9099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\r\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\r\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\r\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\r\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\r\n",
      "\r\n",
      "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\r\n",
      "    Setting a new token will erase the existing one.\r\n",
      "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\r\n",
      "Enter your token (input will not be visible): "
     ]
    }
   ],
   "source": [
    "!huggingface-cli login\n",
    "from huggingface_hub import login\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd4089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in folio data\n",
    "import pandas as pd\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "splits = {'train': 'folio_v2_train.jsonl', 'validation': 'folio_v2_validation.jsonl'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "718dc2e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "GatedRepoError",
     "evalue": "403 Client Error. (Request ID: Root=1-675799d7-72b1b2ba28fd8e961720e9eb;92e58125-1f75-4202-9c46-79d03372e56e)\n\nCannot access gated repo for url https://huggingface.co/datasets/yale-nlp/FOLIO/resolve/main/folio_v2_train.jsonl.\nAccess to dataset yale-nlp/FOLIO is restricted and you are not in the authorized list. Visit https://huggingface.co/datasets/yale-nlp/FOLIO to ask for access.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:406\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/shared/bin/anaconda3/lib/python3.12/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://huggingface.co/datasets/yale-nlp/FOLIO/resolve/main/folio_v2_train.jsonl",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf://datasets/yale-nlp/FOLIO/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m splits[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m], lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/shared/bin/anaconda3/lib/python3.12/site-packages/pandas/io/json/_json.py:791\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    789\u001b[0m     convert_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m json_reader \u001b[38;5;241m=\u001b[39m JsonReader(\n\u001b[1;32m    792\u001b[0m     path_or_buf,\n\u001b[1;32m    793\u001b[0m     orient\u001b[38;5;241m=\u001b[39morient,\n\u001b[1;32m    794\u001b[0m     typ\u001b[38;5;241m=\u001b[39mtyp,\n\u001b[1;32m    795\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    796\u001b[0m     convert_axes\u001b[38;5;241m=\u001b[39mconvert_axes,\n\u001b[1;32m    797\u001b[0m     convert_dates\u001b[38;5;241m=\u001b[39mconvert_dates,\n\u001b[1;32m    798\u001b[0m     keep_default_dates\u001b[38;5;241m=\u001b[39mkeep_default_dates,\n\u001b[1;32m    799\u001b[0m     precise_float\u001b[38;5;241m=\u001b[39mprecise_float,\n\u001b[1;32m    800\u001b[0m     date_unit\u001b[38;5;241m=\u001b[39mdate_unit,\n\u001b[1;32m    801\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m    802\u001b[0m     lines\u001b[38;5;241m=\u001b[39mlines,\n\u001b[1;32m    803\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    804\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m    805\u001b[0m     nrows\u001b[38;5;241m=\u001b[39mnrows,\n\u001b[1;32m    806\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    807\u001b[0m     encoding_errors\u001b[38;5;241m=\u001b[39mencoding_errors,\n\u001b[1;32m    808\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    809\u001b[0m     engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[1;32m    810\u001b[0m )\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "File \u001b[0;32m/shared/bin/anaconda3/lib/python3.12/site-packages/pandas/io/json/_json.py:905\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mujson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    904\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data_from_filepath(filepath_or_buffer)\n\u001b[0;32m--> 905\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[0;32m/shared/bin/anaconda3/lib/python3.12/site-packages/pandas/io/json/_json.py:917\u001b[0m, in \u001b[0;36mJsonReader._preprocess_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunksize \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrows):\n\u001b[1;32m    916\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 917\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunksize \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrows):\n\u001b[1;32m    919\u001b[0m     data \u001b[38;5;241m=\u001b[39m StringIO(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:756\u001b[0m, in \u001b[0;36mHfFileSystemFile.read\u001b[0;34m(self, length)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m length \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m, block_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:  \u001b[38;5;66;03m# block_size=0 enables fast streaming\u001b[39;00m\n\u001b[0;32m--> 756\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mread(length)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:820\u001b[0m, in \u001b[0;36mHfFileSystemStreamFile.read\u001b[0;34m(self, length)\u001b[0m\n\u001b[1;32m    805\u001b[0m     url \u001b[38;5;241m=\u001b[39m hf_hub_url(\n\u001b[1;32m    806\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolved_path\u001b[38;5;241m.\u001b[39mrepo_id,\n\u001b[1;32m    807\u001b[0m         revision\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolved_path\u001b[38;5;241m.\u001b[39mrevision,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    810\u001b[0m         endpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39mendpoint,\n\u001b[1;32m    811\u001b[0m     )\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;241m=\u001b[39m http_backoff(\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    814\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    818\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mconstants\u001b[38;5;241m.\u001b[39mHF_HUB_DOWNLOAD_TIMEOUT,\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 820\u001b[0m     hf_raise_for_status(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse)\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    822\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m*\u001b[39mread_args)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:423\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGatedRepo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    420\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    421\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    422\u001b[0m     )\n\u001b[0;32m--> 423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(GatedRepoError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_message \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess to this resource is disabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    426\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess to this resource is disabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    432\u001b[0m     )\n",
      "\u001b[0;31mGatedRepoError\u001b[0m: 403 Client Error. (Request ID: Root=1-675799d7-72b1b2ba28fd8e961720e9eb;92e58125-1f75-4202-9c46-79d03372e56e)\n\nCannot access gated repo for url https://huggingface.co/datasets/yale-nlp/FOLIO/resolve/main/folio_v2_train.jsonl.\nAccess to dataset yale-nlp/FOLIO is restricted and you are not in the authorized list. Visit https://huggingface.co/datasets/yale-nlp/FOLIO to ask for access."
     ]
    }
   ],
   "source": [
    "train = pd.read_json(\"hf://datasets/yale-nlp/FOLIO/\" + splits[\"train\"], lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce102c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['premises'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert premise FOL to nltk representation so that we can convert to expression to ultimately pass to prover\n",
    "\n",
    "### Temporary provisional use\n",
    "######\n",
    "# function citation: \n",
    "# from https://github.com/benlipkin/linc/blob/main/eval/tasks/utils.py\n",
    "######\n",
    "def convert_to_nltk_rep(logic_formula):\n",
    "    translation_map = {\n",
    "        \"∀\": \"all \",\n",
    "        \"∃\": \"exists \",\n",
    "        \"→\": \"->\",\n",
    "        \"¬\": \"-\",\n",
    "        \"∧\": \"&\",\n",
    "        \"∨\": \"|\",\n",
    "        \"⟷\": \"<->\",\n",
    "        \"↔\": \"<->\",\n",
    "        \"0\": \"Zero\",\n",
    "        \"1\": \"One\",\n",
    "        \"2\": \"Two\",\n",
    "        \"3\": \"Three\",\n",
    "        \"4\": \"Four\",\n",
    "        \"5\": \"Five\",\n",
    "        \"6\": \"Six\",\n",
    "        \"7\": \"Seven\",\n",
    "        \"8\": \"Eight\",\n",
    "        \"9\": \"Nine\",\n",
    "        \".\": \"Dot\",\n",
    "        \"Ś\": \"S\",\n",
    "        \"ą\": \"a\",\n",
    "        \"’\": \"\",\n",
    "    }\n",
    "\n",
    "    constant_pattern = r'\\b([a-z]{2,})(?!\\()'\n",
    "    logic_formula = re.sub(constant_pattern, lambda match: match.group(1).capitalize(), logic_formula)\n",
    "\n",
    "    for key, value in translation_map.items():\n",
    "        logic_formula = logic_formula.replace(key, value)\n",
    "\n",
    "    quant_pattern = r\"(all\\s|exists\\s)([a-z])\"\n",
    "    def replace_quant(match):\n",
    "        return match.group(1) + match.group(2) + \".\"\n",
    "    logic_formula = re.sub(quant_pattern, replace_quant, logic_formula)\n",
    "\n",
    "    dotted_param_pattern = r\"([a-z])\\.(?=[a-z])\"\n",
    "    def replace_dotted_param(match):\n",
    "        return match.group(1)\n",
    "    logic_formula = re.sub(dotted_param_pattern, replace_dotted_param, logic_formula)\n",
    "\n",
    "    simple_xor_pattern = r\"(\\w+\\([^()]*\\)) ⊕ (\\w+\\([^()]*\\))\"\n",
    "    def replace_simple_xor(match):\n",
    "        return (\"((\" + match.group(1) + \" & -\" + match.group(2) + \") | (-\" + match.group(1) + \" & \" + match.group(2) + \"))\")\n",
    "    logic_formula = re.sub(simple_xor_pattern, replace_simple_xor, logic_formula)\n",
    "\n",
    "    complex_xor_pattern = r\"\\((.*?)\\)\\) ⊕ \\((.*?)\\)\\)\"\n",
    "    def replace_complex_xor(match):\n",
    "        return (\"(((\" + match.group(1) + \")) & -(\" + match.group(2) + \"))) | (-(\" + match.group(1) + \")) & (\" + match.group(2) + \"))))\")\n",
    "    logic_formula = re.sub(complex_xor_pattern, replace_complex_xor, logic_formula)\n",
    "\n",
    "    special_xor_pattern = r\"\\(\\(\\((.*?)\\)\\)\\) ⊕ (\\w+\\([^()]*\\))\"\n",
    "    def replace_special_xor(match):\n",
    "        return (\"(((\" + match.group(1) + \")) & -\" + match.group(2) + \") | (-(\" + match.group(1) + \")) & \" + match.group(2) + \")\")\n",
    "    logic_formula = re.sub(special_xor_pattern, replace_special_xor, logic_formula)\n",
    "    \n",
    "    return logic_formula\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ec79a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['premises-FOL'] = [ convert_to_nltk_rep(p) for p in train['premises-FOL']]\n",
    "train['conclusion-FOL'] = train['conclusion-FOL'].apply(convert_to_nltk_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286ae446",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 23\n",
    "n = 60\n",
    "n = 148\n",
    "n= 261\n",
    "\n",
    "# test\n",
    "#n = 850\n",
    "\n",
    "print(train['label'][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48086646",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(train['premises'][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb89939",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['conclusion'][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1895a22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train['premises-FOL'][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e655909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train['conclusion-FOL'][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9f42f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for p, f in zip(train['premises'][n].split('\\n'), train['premises-FOL'][n].split('\\n')):\n",
    "    print(f\"TEXT: {p.strip()}\\nFOL: {f.strip()}\\n\")\n",
    "print(f\"TEXT: {train['conclusion'][n].strip()}\\nFOL: {train['conclusion-FOL'][n].strip()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c406c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build prompt\n",
    "\n",
    "normalFragment = \"\"\"The following is a first-order logic (FOL) problem.\n",
    "The problem is to determine whether the conclusion follows from the premises.\n",
    "The premises are given in the form of a set of first-order logic sentences.\n",
    "The conclusion is given in the form of a single first-order logic sentence.\n",
    "The task is to translate each of the premises and conclusions into FOL expressions, so that the expressions can be evaluated by a theorem solver to determine whether the conclusion follows from the premises.\n",
    "Expressions should adhere to the format of the Python NLTK package logic module.\n",
    "\n",
    "Here are four examples of premises and corresponding FOL.\n",
    "\n",
    "TEXT: A La Liga soccer team ranks higher than another La Liga soccer team if it receives more points.\n",
    "FOL: all x. all y. (LaLigaSoccerTeam(x) & LaLigaSoccerTeam(y) & MorePoints(x, y) -> RankHigherThan(x, y))\n",
    "\n",
    "TEXT: If there are two La Liga soccer teams and neither has more points than the other, then the team which receives more points from the games between the two teams ranks higher.\n",
    "FOL: all x. all y. (LaLigaSoccerTeam(x) & LaLigaSoccerTeam(y) & -MorePoints(x, y) & -MorePoints(y, x) & MorePointsInGameBetween(x, y) ->  RankHigherThan(x, y))\n",
    "\n",
    "TEXT: Real Madrid and Barcelona are both La Liga soccer teams.\n",
    "FOL: LaLigaSoccerTeam(RealMadrid) & LaLigaSoccerTeam(Barcelona)\n",
    "\n",
    "TEXT: Real Madrid received more points than Barcelona.\n",
    "FOL: MorePoints(RealMadrid, Barcelona)\n",
    "\n",
    "TEXT: Neither Real Madrid nor Barcelona received more points from the games between them.\n",
    "FOL: -MorePointsInGameBetween(RealMadrid, Barcelona) & -MorePointsInGameBetween(Barcelona, RealMadrid)\n",
    "\n",
    "TEXT: Real Madrid ranks higher than Barcelona.\n",
    "FOL: RankHigherThan(RealMadrid, Barcelona)\n",
    "<EVALUATE>\n",
    "\n",
    "TEXT: All professional athletes spend most of their time on sports.\n",
    "FOL: all x. (ProfessionalAthlete(x) -> SpendOn(x, MostOfTheirTime, Sports))\n",
    "\n",
    "TEXT: All Olympic gold medal winners are professional athletes.\n",
    "FOL: all x. (OlympicGoldMedalWinner(x) -> ProfessionalAthlete(x))\n",
    "\n",
    "TEXT: No full-time scientists spend the majority of their time on sports.\n",
    "FOL: all x. (FullTimeScientist(x) -> -SpendOn(x, MostOfTheirTime, Sports))\n",
    "\n",
    "TEXT: All Nobel physics laureates are full-time scientists.\n",
    "FOL: all x. (NobelPhysicsLaureate(x) -> FullTimeScientist(x))\n",
    "\n",
    "TEXT: Amy spends the most time on sports, or Amy is an Olympic gold medal winner.\n",
    "FOL: SpendOn(Amy, MostOfTheirTime, Sports) | OlympicGoldMedalWinner(Amy)\n",
    "\n",
    "TEXT: If Amy is not a Nobel physics laureate, then Amy is not an Olympic gold medal winner.\n",
    "FOL: -NobelPhysicsLaureate(Amy) -> -OlympicGoldMedalWinner(Amy)\n",
    "\n",
    "TEXT: If Amy is not an Olympic gold medal winner, then Amy is a Nobel physics laureate.\n",
    "FOL: -OlympicGoldMedalWinner(Amy) -> NobelPhysicsLaureate(Amy)\n",
    "<EVALUATE>\n",
    "\n",
    "TEXT: No songs are visuals.\n",
    "FOL: all x. (Song(x) -> -Visual(x))\n",
    "\n",
    "TEXT: All folk songs are songs.\n",
    "FOL: all x. (FolkSong(x) -> Song(x))\n",
    "\n",
    "TEXT: All videos are visuals.\n",
    "FOL: all x. (Video(x) -> Visual(x))\n",
    "\n",
    "TEXT: All movies are videos.\n",
    "FOL: all x. (Movie(x) -> Video(x))\n",
    "\n",
    "TEXT: All sci-fi movies are movies.\n",
    "FOL: all x. (ScifiMovie(x) -> Movie(x))\n",
    "\n",
    "TEXT: Inception is a sci-fi movie.\n",
    "FOL: ScifiMovie(Inception)\n",
    "\n",
    "TEXT: Mac is neither a folk song nor a sci-fi movie.\n",
    "FOL: -FolkSong(Mac) & -ScifiMovie(Mac)\n",
    "\n",
    "TEXT: Inception is a folk song.\n",
    "FOL: FolkSong(Inception)\n",
    "<EVALUATE>\n",
    "\n",
    "TEXT: Every chef can cook.\n",
    "FOL: all x. (Chef(x) -> Can(x, Cook))\n",
    "\n",
    "TEXT: Some people who aren’t chefs can cook.\n",
    "FOL: exists x. (-Chef(x) & Can(x, Cook))\n",
    "\n",
    "TEXT: People who cook can make scrambled eggs and pasta.\n",
    "FOL: all x. (Can(x, Cook) -> (CanMake(x, ScrambledEggs) & CanMake(x, Pasta)))\n",
    "\n",
    "TEXT: If someone can make cookies and muffins, they are a baker.\n",
    "FOL: all x. (CanMake(x, Cookies) & CanMake(x, Muffins) -> Baker(x))\n",
    "\n",
    "TEXT: Bakers who can also make scrambled eggs can make a good breakfast.\n",
    "FOL: all x. ((Baker(x) & CanMake(x, ScrambledEggs)) -> CanMake(x, GoodBreakfast))\n",
    "\n",
    "TEXT: Luke can make cookies, scrambled eggs, and muffins, but not pasta.\n",
    "FOL: CanMake(Luke, Cookies) & (CanMake(Luke, ScrambledEggs) & CanMake(Luke, Muffins) & -CanMake(Luke, Pasta)\n",
    "\n",
    "TEXT: Luke is a chef.\n",
    "FOL: Chef(Luke)\n",
    "<EVALUATE>\n",
    "\n",
    "Translate the following premises and conclusions to FOL expressions that are parseable by NLTK.\n",
    "Only output the expressions.\n",
    "<PREMISES>\n",
    "\"\"\"\n",
    "\n",
    "bnfFragment = \"\"\"The following is a first-order logic (FOL) problem.\n",
    "The problem is to determine whether the conclusion follows from the premises.\n",
    "The premises are given in the form of a set of first-order logic sentences.\n",
    "The conclusion is given in the form of a single first-order logic sentence.\n",
    "The task is to translate each of the premises and conclusions into FOL expressions, so that the expressions can be evaluated by a theorem solver to determine whether the conclusion follows from the premises.\n",
    "Expressions should adhere to the format of the Python NLTK package logic module.\n",
    "\n",
    "Follow the following Backus-Naur Form grammar to construct your expression. Example usages precede each rule in comments.\n",
    "```\n",
    "// Example: all x. (ProfessionalAthlete(x) -> SpendOn(x, MostOfTheirTime, Sports))\n",
    "<Expression> ::= <UniversalQuantifier> | <ExistentialQuantifier> | <Predicate> | <Not> | <And> | <Or> | <Implication> | <Biconditional> | <ParenthesizedExpression>\n",
    "\n",
    "// Example: all x. (Chef(x) -> Can(x, Cook))\n",
    "<UniversalQuantifier> ::= \"all\" <Variable> . <Expression>\n",
    "\n",
    "// Example: exists x. (-Chef(x) & Can(x, Cook))\n",
    "<ExistentialQuantifier> ::= \"exists\" <Variable> . <Expression>\n",
    "\n",
    "// Example: x\n",
    "<Variable> ::= \"x\" | \"y\" | \"z\" | <name>\n",
    "\n",
    "// Example: LaLigaSoccerTeam(RealMadrid)\n",
    "<Predicate> ::= <name> \"(\" <Terms> \")\"\n",
    "\n",
    "// Example: CanMake(Luke, ScrambledEggs, Muffins)\n",
    "<Terms> ::= <Term> | <Term> \",\" <Terms>\n",
    "\n",
    "// Example: x or RealMadrid\n",
    "<Term> ::= <Variable> | <Constant>\n",
    "\n",
    "// Example: RealMadrid\n",
    "<Constant> ::= <name>\n",
    "\n",
    "// Example: -OlympicGoldMedalWinner(Amy)\n",
    "<Not> ::= \"-\" <Expression>\n",
    "\n",
    "// Example: LaLigaSoccerTeam(RealMadrid) & LaLigaSoccerTeam(Barcelona)\n",
    "<And> ::= <Expression> \"&\" <Expression>\n",
    "\n",
    "// Example: SpendOn(Amy, MostOfTheirTime, Sports) | OlympicGoldMedalWinner(Amy)\n",
    "<Or> ::= <Expression> \"|\" <Expression>\n",
    "\n",
    "// Example: -NobelPhysicsLaureate(Amy) -> -OlympicGoldMedalWinner(Amy)\n",
    "<Implication> ::= <Expression> \"->\" <Expression>\n",
    "\n",
    "// Example: -OlympicGoldMedalWinner(Amy) -> NobelPhysicsLaureate(Amy)\n",
    "<Biconditional> ::= <Expression> \"<->\" <Expression>\n",
    "\n",
    "// Example: (LaLigaSoccerTeam(x) & LaLigaSoccerTeam(y) & MorePoints(x, y) -> RankHigherThan(x, y))\n",
    "<ParenthesizedExpression> ::= \"(\" <Expression> \")\"\n",
    "\n",
    "// Example: RealMadrid\n",
    "<name> ::= <letter> <letters>\n",
    "\n",
    "// Example: R\n",
    "<letter> ::= \"a\" | \"b\" | \"c\" | ... | \"z\" | \"A\" | \"B\" | \"C\" | ... | \"Z\"\n",
    "\n",
    "// Example: RealMadrid\n",
    "<letters> ::= <letter> | <letter> <letters>\n",
    "\n",
    "```\n",
    "\n",
    "Here are four examples of premises and corresponding FOL.\n",
    "\n",
    "TEXT: A La Liga soccer team ranks higher than another La Liga soccer team if it receives more points.\n",
    "FOL: all x. all y. (LaLigaSoccerTeam(x) & LaLigaSoccerTeam(y) & MorePoints(x, y) -> RankHigherThan(x, y))\n",
    "\n",
    "TEXT: If there are two La Liga soccer teams and neither has more points than the other, then the team which receives more points from the games between the two teams ranks higher.\n",
    "FOL: all x. all y. (LaLigaSoccerTeam(x) & LaLigaSoccerTeam(y) & -MorePoints(x, y) & -MorePoints(y, x) & MorePointsInGameBetween(x, y) ->  RankHigherThan(x, y))\n",
    "\n",
    "TEXT: Real Madrid and Barcelona are both La Liga soccer teams.\n",
    "FOL: LaLigaSoccerTeam(RealMadrid) & LaLigaSoccerTeam(Barcelona)\n",
    "\n",
    "TEXT: Real Madrid received more points than Barcelona.\n",
    "FOL: MorePoints(RealMadrid, Barcelona)\n",
    "\n",
    "TEXT: Neither Real Madrid nor Barcelona received more points from the games between them.\n",
    "FOL: -MorePointsInGameBetween(RealMadrid, Barcelona) & -MorePointsInGameBetween(Barcelona, RealMadrid)\n",
    "\n",
    "TEXT: Real Madrid ranks higher than Barcelona.\n",
    "FOL: RankHigherThan(RealMadrid, Barcelona)\n",
    "<EVALUATE>\n",
    "\n",
    "TEXT: All professional athletes spend most of their time on sports.\n",
    "FOL: all x. (ProfessionalAthlete(x) -> SpendOn(x, MostOfTheirTime, Sports))\n",
    "\n",
    "TEXT: All Olympic gold medal winners are professional athletes.\n",
    "FOL: all x. (OlympicGoldMedalWinner(x) -> ProfessionalAthlete(x))\n",
    "\n",
    "TEXT: No full-time scientists spend the majority of their time on sports.\n",
    "FOL: all x. (FullTimeScientist(x) -> -SpendOn(x, MostOfTheirTime, Sports))\n",
    "\n",
    "TEXT: All Nobel physics laureates are full-time scientists.\n",
    "FOL: all x. (NobelPhysicsLaureate(x) -> FullTimeScientist(x))\n",
    "\n",
    "TEXT: Amy spends the most time on sports, or Amy is an Olympic gold medal winner.\n",
    "FOL: SpendOn(Amy, MostOfTheirTime, Sports) | OlympicGoldMedalWinner(Amy)\n",
    "\n",
    "TEXT: If Amy is not a Nobel physics laureate, then Amy is not an Olympic gold medal winner.\n",
    "FOL: -NobelPhysicsLaureate(Amy) -> -OlympicGoldMedalWinner(Amy)\n",
    "\n",
    "TEXT: If Amy is not an Olympic gold medal winner, then Amy is a Nobel physics laureate.\n",
    "FOL: -OlympicGoldMedalWinner(Amy) -> NobelPhysicsLaureate(Amy)\n",
    "<EVALUATE>\n",
    "\n",
    "TEXT: No songs are visuals.\n",
    "FOL: all x. (Song(x) -> -Visual(x))\n",
    "\n",
    "TEXT: All folk songs are songs.\n",
    "FOL: all x. (FolkSong(x) -> Song(x))\n",
    "\n",
    "TEXT: All videos are visuals.\n",
    "FOL: all x. (Video(x) -> Visual(x))\n",
    "\n",
    "TEXT: All movies are videos.\n",
    "FOL: all x. (Movie(x) -> Video(x))\n",
    "\n",
    "TEXT: All sci-fi movies are movies.\n",
    "FOL: all x. (ScifiMovie(x) -> Movie(x))\n",
    "\n",
    "TEXT: Inception is a sci-fi movie.\n",
    "FOL: ScifiMovie(Inception)\n",
    "\n",
    "TEXT: Mac is neither a folk song nor a sci-fi movie.\n",
    "FOL: -FolkSong(Mac) & -ScifiMovie(Mac)\n",
    "\n",
    "TEXT: Inception is a folk song.\n",
    "FOL: FolkSong(Inception)\n",
    "<EVALUATE>\n",
    "\n",
    "TEXT: Every chef can cook.\n",
    "FOL: all x. (Chef(x) -> Can(x, Cook))\n",
    "\n",
    "TEXT: Some people who aren’t chefs can cook.\n",
    "FOL: exists x. (-Chef(x) & Can(x, Cook))\n",
    "\n",
    "TEXT: People who cook can make scrambled eggs and pasta.\n",
    "FOL: all x. (Can(x, Cook) -> (CanMake(x, ScrambledEggs) & CanMake(x, Pasta)))\n",
    "\n",
    "TEXT: If someone can make cookies and muffins, they are a baker.\n",
    "FOL: all x. (CanMake(x, Cookies) & CanMake(x, Muffins) -> Baker(x))\n",
    "\n",
    "TEXT: Bakers who can also make scrambled eggs can make a good breakfast.\n",
    "FOL: all x. ((Baker(x) & CanMake(x, ScrambledEggs)) -> CanMake(x, GoodBreakfast))\n",
    "\n",
    "TEXT: Luke can make cookies, scrambled eggs, and muffins, but not pasta.\n",
    "FOL: CanMake(Luke, Cookies) & (CanMake(Luke, ScrambledEggs) & CanMake(Luke, Muffins) & -CanMake(Luke, Pasta)\n",
    "\n",
    "TEXT: Luke is a chef.\n",
    "FOL: Chef(Luke)\n",
    "<EVALUATE>\n",
    "\n",
    "\n",
    "Translate the following premises and conclusions to FOL expressions that are parseable by NLTK.\n",
    "Only output the expressions.\n",
    "<PREMISES>\n",
    "\"\"\"\n",
    "\n",
    "theRest = \"\"\"Surprises are either fun or dreadful.\n",
    "All scares are surprises.\n",
    "</PREMISES>\n",
    "<CONCLUSION>\n",
    "All scares are fun.\n",
    "</CONCLUSION>\n",
    "<EVALUATE>\n",
    "\"\"\"\n",
    "\n",
    "def genPrompt(fragment, premises, conclusion):\n",
    "    return fragment + premises + \"\\n</PREMISES>\\n<CONCLUSION>\" + conclusion + \"\\n</CONCLUSION>\\n<EVALUATE>\\n\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "validation = pd.read_json(\"hf://datasets/yale-nlp/FOLIO/\" + splits[\"validation\"], lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f6c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(validation)):\n",
    "    print(validation['premises'][i])\n",
    "    #validation['conclusion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c199fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "\n",
    "api_key = \"AIzaSyCwtF9WNpBGf28_CTJKmaUqqXW843lM94c\"\n",
    "\n",
    "def call_api(key, prompt):\n",
    "    data = {\n",
    "        \"contents\": [\n",
    "            {\n",
    "                \"parts\": [\n",
    "                    {\n",
    "                        \"text\": prompt\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    command = [\n",
    "        \"curl\",\n",
    "\n",
    "        \"-H\", \"Content-Type: application/json\",\n",
    "        \"-d\", json.dumps(data),\n",
    "        \"-X\", \"POST\", f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key={key}\",\n",
    "\n",
    "    ]\n",
    "\n",
    "    result = subprocess.run(command, capture_output=True, text=True) \n",
    "    response_json = json.loads(result.stdout)\n",
    "    return response_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbe8c3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = call_api(api_key, normalFragment)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa512a3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70b45ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "genPrompt(normalFragment, validation['premises'][0], validation['conclusion'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9445466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def process_dataset(dataset, fragment, rate_limit):\n",
    "    start = time.time()\n",
    "    lst = []\n",
    "    numParsedExprs = 0\n",
    "    numTotalExprs = 0\n",
    "    for i in range(len(dataset)):\n",
    "        # rate limit\n",
    "        #if (i + 1) % rate_limit == 0:\n",
    "        #    since = time.time() - start\n",
    "        #    if since < 60:\n",
    "        #       time.sleep(60 - since)\n",
    "        #    start = time.time()\n",
    "            \n",
    "        premises = dataset['premises'][i]\n",
    "        conclusion = dataset['conclusion'][i]\n",
    "         \n",
    "        # call api\n",
    "        r = call_api(api_key, genPrompt(fragment, premises, conclusion))\n",
    "        print(r)\n",
    "        print(i, \"called API\")\n",
    "        r = r['candidates'][0]['content']['parts'][0]['text'].split('\\n')\n",
    "        r = [l for l in r if not l.startswith(\"`\")]\n",
    "        \n",
    "        wasException = False\n",
    "        \n",
    "        # parse as nltk Expression\n",
    "        for l in r:\n",
    "            numTotalExprs+=1\n",
    "            try:\n",
    "                expr = Expression.fromstring(l)\n",
    "                numParsedExprs+=1\n",
    "                print(i, expr)\n",
    "            except Exception as e:\n",
    "                wasException = True\n",
    "                continue\n",
    "\n",
    "        if not wasException:\n",
    "            lst.append(i)\n",
    "    print(\"number of parsed exprs: \", numParsedExprs)\n",
    "    print(\"number of total exprs: \", numTotalExprs)\n",
    "    return lst\n",
    " \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2769ab3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lst = process_dataset(validation, bnfFragment, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a036b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141c0a08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lst2 = process_dataset(validation, bnfFragment, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d292e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a304bd0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "normalLst = process_dataset(validation, normalFragment, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd53c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(normalLst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27117b66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "jsonstr = json.dumps(lst)\n",
    "\n",
    "with open('normal.json', 'w') as file: \n",
    "    file.write(jsonstr)\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Create a link to the file\n",
    "display(FileLink('normal.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c703577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst2 = process_dataset(validation, bnf, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2058738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26468481",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70146f9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lines = res['candidates'][0]['content']['parts'][0]['text'].split('\\n')\n",
    "#lines = [reformat_fol(l) for l in lines]\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8d58b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a098f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Expression.fromstring(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfab5208",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"'All xDot (Surprise(x) -> (Fun(x) | Dreadful(x)))\\nAll xDot (Scare(x) -> Surprise(x))\\nAll xDot (Scare(x) -> Fun(x))\\n'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80463b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4c6d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8637e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c0eb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dca0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c800ec6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b86c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bigcode/santacoder\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"bigcode/santacoder\", trust_remote_code=True)\n",
    "\n",
    "inputs = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f7191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt the model\n",
    "\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bigcode/santacoder\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"bigcode/santacoder\", trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# using normal prompt\n",
    "inputs_n = tokenizer(normal, return_tensors=\"pt\",truncation=True)\n",
    "outputs_n = model.generate(**inputs_n, max_new_tokens=200, do_sample=True, temperature=0.7) \n",
    "\n",
    "output_final_n = tokenizer.decode(outputs_n[0], skip_special_tokens=True)\n",
    "\n",
    "print(output_final_n)\n",
    "\n",
    "\n",
    "# using bnf prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fef57e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6741ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f851afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for prelim results 1: convert to  nltk expression + apply grammar (check for correctness of expression l8r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af142936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cs375 final)",
   "language": "python",
   "name": "cs375final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
